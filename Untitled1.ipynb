{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQkCTH0CoNbM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import json\n",
        "from collections import Counter\n",
        "import random\n",
        "import sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 10\n",
        "\n",
        "# Load JSON file\n",
        "# Change to appropriate graph\n",
        "filepath = '/Users/velis.christ/Downloads/'\n",
        "filename = 'RR.10.50.json'\n",
        "with open(filepath+filename) as f:\n",
        "    adj_list = json.load(f)\n",
        "\n",
        "# Create a graph\n",
        "G = nx.Graph(adj_list)\n",
        "\n",
        "# Compute centralities\n",
        "deg_cent = nx.degree_centrality(G)\n",
        "close_cent = nx.closeness_centrality(G)\n",
        "bet_cent = nx.betweenness_centrality(G)\n",
        "\n",
        "# Might not always be 5\n",
        "i = 10\n",
        "close_top_10 = [entry[0] for entry in sorted(deg_cent.items(), key=lambda x: x[1], reverse=True)[:i]]\n",
        "deg_top_10 = [entry[0] for entry in sorted(close_cent.items(), key=lambda x: x[1], reverse=True)[:i]]\n",
        "bet_top_10 = [entry[0] for entry in sorted(bet_cent.items(), key=lambda x: x[1], reverse=True)[:i]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def algo_1(num_seed_nodes):\n",
        "    deg_cent = nx.degree_centrality(G)\n",
        "    close_cent = nx.closeness_centrality(G)\n",
        "    bet_cent = nx.betweenness_centrality(G)\n",
        "\n",
        "    # Might not always be 5\n",
        "    i = 5\n",
        "    close_top_10 = [entry[0] for entry in sorted(deg_cent.items(), key=lambda x: x[1], reverse=True)[:i]]\n",
        "    deg_top_10 = [entry[0] for entry in sorted(close_cent.items(), key=lambda x: x[1], reverse=True)[:i]]\n",
        "    bet_top_10 = [entry[0] for entry in sorted(bet_cent.items(), key=lambda x: x[1], reverse=True)[:i]]\n",
        "\n",
        "    s = set(close_top_10).union(set(deg_top_10), set(bet_top_10))\n",
        "    return random.choices(list(s), k=num_seed_nodes)\n",
        "\n",
        "def algo_1(n):\n",
        "    deg_cent = nx.closeness_centrality(G)\n",
        "    close_top_5 = [entry[0] for entry in sorted(deg_cent.items(), key=lambda x: x[1], reverse=True)[:n]]\n",
        "    return close_top_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def algo_2(N):\n",
        "  \"\"\"\n",
        "  A function to get N seeds for a graph given by filename\n",
        "\n",
        "  N: the number of seeds for a graph\n",
        "  filename: the filename for (in json format) for the graph representation\n",
        "  \"\"\"\n",
        "  G = nx.Graph(adj_list)\n",
        "  # Return every node if N is greater than the number of nodes in the graph\n",
        "  if N >= len(list(G.nodes())):\n",
        "    return list(G.nodes())\n",
        "  \n",
        "  # Rough idea is to find all components, put at least one in each, then scale based on size of each\n",
        "  comps = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "  comp_len = [len(c) for c in comps]\n",
        "\n",
        "  # Iterate through each connected component and select the vertex with the highest centrality measure\n",
        "  # Closeness centrality selected off of very little thought\n",
        "  ans = []\n",
        "  if len(comp_len) >= N:\n",
        "    for idx in range(len(comp_len)):\n",
        "      component = comps[idx]\n",
        "      vals = nx.closeness_centrality(G.subgraph(component))\n",
        "      for k,v in Counter.most_common(vals,1):\n",
        "        ans.append(k)\n",
        "\n",
        "  # If there are more components in one than the other, put all in largest (temporary idea)\n",
        "  # Better idea may be to put a proportional number of nodes per component size after 1 in each\n",
        "  else:\n",
        "    num_extra = N - len(comp_len)\n",
        "    curr_taken = 0\n",
        "    for component in comps:\n",
        "      vals = nx.closeness_centrality(G.subgraph(component))\n",
        "      nodes = list(G.subgraph(component).nodes())\n",
        "      comp_size = len(nodes) # size of component\n",
        "      # Extra nodes added to components already, take highest in component\n",
        "      if curr_taken == num_extra:\n",
        "        for k,v in Counter.most_common(vals,1):\n",
        "          ans.append(k)\n",
        "      # Component doesn't have enough nodes to fill N\n",
        "      elif (comp_size-1) < (num_extra-curr_taken):\n",
        "        # Just add every node\n",
        "        for node in nodes:\n",
        "          ans.append(node)\n",
        "        curr_taken += comp_size-1\n",
        "      else:\n",
        "        for k,v in Counter.most_common(vals, num_extra-curr_taken+1):\n",
        "          ans.append(k)\n",
        "        curr_taken += num_extra-curr_taken\n",
        "    \n",
        "  if len(ans) != N:\n",
        "    print(\"Something went wrong\")\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def algo_3(n):\n",
        "    bet_cent = nx.degree_centrality(G)\n",
        "    close_cent = nx.closeness_centrality(G)\n",
        "    bet_top = [entry[0] for entry in sorted(bet_cent.items(), key=lambda x: x[1], reverse=True)[:n]]\n",
        "    close_top = [entry[0] for entry in sorted(close_cent.items(), key=lambda x: x[1], reverse=True)[:n]]\n",
        "    val = None\n",
        "    for i in bet_top:\n",
        "        if i not in close_top:\n",
        "            val = i\n",
        "            break\n",
        "    if val != None:\n",
        "        close_top[-1] = val\n",
        "    return close_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def algo_4(n):\n",
        "    bet_cent = nx.betweenness_centrality(G)\n",
        "    close_cent = nx.closeness_centrality(G)\n",
        "    deg_cent = nx.degree_centrality(G)\n",
        "    new_cent = {}\n",
        "    for node in bet_cent:\n",
        "        if node in close_cent and node in deg_cent:\n",
        "            new_cent[node] = 0.3*bet_cent[node]+close_cent[node]+0*deg_cent[node]\n",
        "    new_top = [entry[0] for entry in sorted(new_cent.items(), key=lambda x: x[1], reverse=True)[:n]]\n",
        "    return new_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ibet_cent = nx.betweenness_centrality(G)\n",
        "iclose_cent = nx.closeness_centrality(G)\n",
        "ideg_cent = nx.degree_centrality(G)\n",
        "def algo_5(n, scale_factor=0.3):\n",
        "    new_cent = {}\n",
        "    for node in ibet_cent:\n",
        "        if node in iclose_cent and node in ideg_cent:\n",
        "            new_cent[node] = scale_factor*ibet_cent[node]+iclose_cent[node]\n",
        "    new_top = [entry[0] for entry in sorted(new_cent.items(), key=lambda x: x[1], reverse=True)[:n]]\n",
        "    return new_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def algo_6(n):\n",
        "    voterank = nx.voterank(G)\n",
        "    voterank_top = voterank[:n]\n",
        "    return voterank_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare(adj_list):\n",
        "    node_mappings = dict()\n",
        "    node_mappings[\"algo 1\"] = algo_1(n)\n",
        "    node_mappings[\"algo 2\"] = algo_2(n)\n",
        "    results = sim.run(adj_list, node_mappings)\n",
        "    print(results)\n",
        "\n",
        "def compare_TA(adj_list):\n",
        "    filepath = '/Users/velis.christ/Downloads/'\n",
        "    filename = 'RR.10.50-TA_hard.json'\n",
        "    with open(filepath+filename) as f:\n",
        "        nodes_TA = json.load(f)\n",
        "    node_mappings = dict()\n",
        "    node_mappings[\"TA\"] = nodes_TA['TA_hard'][1]\n",
        "    node_mappings[\"JYP\"] = algo_4(n)\n",
        "    results = sim.run(adj_list, node_mappings)\n",
        "    print(results)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize(adj_list):\n",
        "    filepath = '/Users/velis.christ/Downloads/'\n",
        "    filename = 'RR.10.50-TA_hard.json'\n",
        "    with open(filepath+filename) as f:\n",
        "        nodes_TA = json.load(f)\n",
        "    node_mappings = dict()\n",
        "    node_mappings[\"TA\"] = nodes_TA['TA_hard'][1]\n",
        "    diff = 0\n",
        "    idx = 0\n",
        "    for i in np.linspace(0,1,num=200):\n",
        "        node_mappings[\"JYP\"] = algo_5(n,i)\n",
        "        results = sim.run(adj_list, node_mappings)\n",
        "        iter_us = results[\"JYP\"]\n",
        "        iter_them = results[\"TA\"]\n",
        "        if iter_us-iter_them >= diff:\n",
        "            diff = iter_us-iter_them\n",
        "            idx = i\n",
        "    return idx, diff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "idx, diff = optimize(adj_list)\n",
        "print(idx, diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_TA(adj_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(50):\n",
        "#     nodes = algo_2(n)\n",
        "#     for node in nodes:\n",
        "#         res += (node + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_mappings = dict()\n",
        "node_mappings[\"algo 1\"] = algo_1(n)\n",
        "results = sim.run(adj_list, node_mappings)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a1 = sorted(algo_1(n))\n",
        "a2 = sorted(algo_2(n))\n",
        "print(a1)\n",
        "print(a2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open the file for writing\n",
        "with open(\"RR.5.20.txt\", \"w\") as f:\n",
        "    # Write the string to the file\n",
        "    f.write(res)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
